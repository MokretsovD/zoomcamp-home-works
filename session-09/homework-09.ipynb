{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c97bf1-d62c-4e3e-bf81-bd4cb5066a1b",
   "metadata": {},
   "source": [
    "# Homework Session-09\n",
    "\n",
    "In this homework, we'll deploy the dogs vs cats model we trained in the previous homework.\n",
    "\n",
    "Download the model from here:\n",
    "\n",
    "[alexeygrigorev/large-datasets@dogs-cats-model dogs_cats_10_0.687.h5 (download)](https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats-model/dogs_cats_10_0.687.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077695ec-6c1d-4ceb-bf88-5171e60a5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdad44f7-5845-4bc5-85af-99542fb4717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-01 19:54:26--  https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats-model/dogs_cats_10_0.687.h5\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/426348925/f4f8406c-b1cd-4377-94a0-8a89b6f826bd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211201T185426Z&X-Amz-Expires=300&X-Amz-Signature=ee8504ffc96656696420bdfa145dc7a83b65f26e0fb49aa9961ef2354d076c0c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Ddogs_cats_10_0.687.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-12-01 19:54:26--  https://github-releases.githubusercontent.com/426348925/f4f8406c-b1cd-4377-94a0-8a89b6f826bd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211201T185426Z&X-Amz-Expires=300&X-Amz-Signature=ee8504ffc96656696420bdfa145dc7a83b65f26e0fb49aa9961ef2354d076c0c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Ddogs_cats_10_0.687.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 89758304 (86M) [application/octet-stream]\n",
      "Saving to: ‘dogs-cats-model.h5’\n",
      "\n",
      "dogs-cats-model.h5  100%[===================>]  85.60M  12.6MB/s    in 6.9s    \n",
      "\n",
      "2021-12-01 19:54:33 (12.4 MB/s) - ‘dogs-cats-model.h5’ saved [89758304/89758304]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats-model/dogs_cats_10_0.687.h5 -O dogs-cats-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2bdd26-d23b-448a-832e-7ef710fe72c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:03:53.855038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-01 20:03:53.855084: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-01 20:03:53.855102: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2021-12-01 20:03:53.878102: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-01 20:03:55.505418: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz6syd2x3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:03:56.509553: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-12-01 20:03:56.509690: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-12-01 20:03:56.566377: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.753ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2021-12-01 20:03:57.490047: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-12-01 20:03:57.490115: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2021-12-01 20:03:57.750643: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('dogs-cats-model.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('dogs-cats-model.tflite','wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507789a-eafe-4b51-bd32-8e681d377c30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "__What's the size of the converted model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4557c89a-b7d2-4e57-b37d-73c64cd22d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44865952 dogs-cats-model.tflite\n"
     ]
    }
   ],
   "source": [
    "!wc -c dogs-cats-model.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf558d18-ef10-48a9-8e67-4ec4e960e6ec",
   "metadata": {},
   "source": [
    "__*Answer Q1: 44865952*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610c131-f214-4491-92cd-829870d7cdc0",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "To be able to use this model, we need to know the index of the input and the index of the output.\n",
    "\n",
    "__What's the output index for this model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1259c8df-323b-4c36-8b75-88a142013649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_index: 0\n",
      "output_index: 13\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "interpreter = tflite.Interpreter(model_path='dogs-cats-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "print('input_index: %s' % input_index)\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "print('output_index: %s' % output_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5380c0-7f01-4de9-9257-c470582a9ba5",
   "metadata": {},
   "source": [
    "__*Answer Q2: 13*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f0fe0b-2650-470a-ab01-4a4ce00ab0e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the image\n",
    "You'll need some code for downloading and resizing images. You can use this code:\n",
    "\n",
    "```Python\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "```   \n",
    "    \n",
    "For that, you'll need to have pillow installed:\n",
    "\n",
    "```Python\n",
    "pip install pillow\n",
    "```\n",
    "\n",
    "Let's download and resize this image:\n",
    "\n",
    "[upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg](https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg)\n",
    "\n",
    "__Based on the solution of the previous homework, what should be the target size for the image?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6a275f-55f8-4637-941d-560c708a45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43a1b9e5-2e6d-43e1-b364-6412ae3e453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/9/9a/Pug_600.jpg'\n",
    "size = (150,150)\n",
    "\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e584026-3dfb-4612-a4d5-9a6c1a5d109f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3\n",
    "Now we need to turn the image into an numpy array and pre-process it.\n",
    "\n",
    "Tip: Check the previous homework. What was the pre-processing we did there?\n",
    "\n",
    "__After the pre-processing, what's the value in the first pixel, the R channel?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35e13608-07b0-4550-a92a-53811be8831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6888c3f5-6cba-425d-b7eb-aa2ff8ac3203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.70588235, 0.77254902, 0.74901961],\n",
       "         [0.69411765, 0.76078431, 0.72941176],\n",
       "         [0.63137255, 0.69803922, 0.66666667],\n",
       "         ...,\n",
       "         [0.76470588, 0.85098039, 0.83921569],\n",
       "         [0.68235294, 0.74509804, 0.74509804],\n",
       "         [0.6745098 , 0.76862745, 0.77647059]],\n",
       "\n",
       "        [[0.5254902 , 0.59215686, 0.56862745],\n",
       "         [0.7372549 , 0.80392157, 0.78039216],\n",
       "         [0.60784314, 0.6745098 , 0.64313725],\n",
       "         ...,\n",
       "         [0.79215686, 0.86666667, 0.85882353],\n",
       "         [0.63137255, 0.70196078, 0.63921569],\n",
       "         [0.78823529, 0.87843137, 0.85490196]],\n",
       "\n",
       "        [[0.68627451, 0.74901961, 0.7372549 ],\n",
       "         [0.61960784, 0.68627451, 0.6627451 ],\n",
       "         [0.64705882, 0.71372549, 0.68235294],\n",
       "         ...,\n",
       "         [0.6       , 0.65882353, 0.64705882],\n",
       "         [0.62745098, 0.69411765, 0.65490196],\n",
       "         [0.70588235, 0.79607843, 0.77254902]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039216, 0.61960784, 0.58431373],\n",
       "         [0.49019608, 0.5254902 , 0.50588235],\n",
       "         [0.56862745, 0.60392157, 0.59215686],\n",
       "         ...,\n",
       "         [0.58039216, 0.59215686, 0.54901961],\n",
       "         [0.4745098 , 0.48627451, 0.44313725],\n",
       "         [0.30196078, 0.33333333, 0.28235294]],\n",
       "\n",
       "        [[0.47058824, 0.51372549, 0.45882353],\n",
       "         [0.47058824, 0.50980392, 0.4745098 ],\n",
       "         [0.59607843, 0.63137255, 0.61176471],\n",
       "         ...,\n",
       "         [0.74901961, 0.74117647, 0.68235294],\n",
       "         [0.17647059, 0.18039216, 0.11764706],\n",
       "         [0.39215686, 0.41568627, 0.36078431]],\n",
       "\n",
       "        [[0.57647059, 0.57647059, 0.5372549 ],\n",
       "         [0.74509804, 0.72156863, 0.66666667],\n",
       "         [0.49803922, 0.53333333, 0.52941176],\n",
       "         ...,\n",
       "         [0.57254902, 0.6       , 0.56862745],\n",
       "         [0.4       , 0.41960784, 0.39215686],\n",
       "         [0.43529412, 0.45490196, 0.42745098]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img)\n",
    "x = x/255\n",
    "X = np.array([x])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ed161-0c2f-4dc2-a0a7-15772eb225ff",
   "metadata": {},
   "source": [
    "__*Answer Q3: 0.70588235*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0088d83-23d7-424f-969b-d6552b645559",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 4\n",
    "__Now let's apply this model to this image. What's the output of the model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0a06ab6-0317-42e8-b241-52f318aa2e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7704913]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778098d6-6230-4b18-8d3d-836622a75222",
   "metadata": {},
   "source": [
    "__*Answer Q4: 0.7704913*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed22c5-c9bc-4923-9d5a-5a144367fd85",
   "metadata": {},
   "source": [
    "## Prepepare the lambda code\n",
    "Now you need to copy all the code into a separate python file. You will need to use this file for the next two questions.\n",
    "\n",
    "Tip: you can test this file locally with ipython or Jupyter Notebook by importing the file and invoking the function from this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387ebc2-78d4-4fdc-a5dc-ad97532ad3d6",
   "metadata": {},
   "source": [
    "## Docker\n",
    "For the next two questions, we'll use a Docker image that I already prepared. This is the Dockerfile that I used for creating the image:\n",
    "\n",
    "```Python\n",
    "FROM public.ecr.aws/lambda/python:3.8\n",
    "COPY cats-dogs-v2.tflite .\n",
    "And pushed it to agrigorev/zoomcamp-cats-dogs-lambda:v2.\n",
    "```\n",
    "\n",
    "Note: The image already contains a model and it's not the same model as the one we used for questions 1-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a6dfe-9adf-4ff1-8443-14e0c61338f3",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Now let's extend this docker image, install all the required libraries and add the code for lambda.\n",
    "\n",
    "You don't need to include the model in the image. It's already included. The name of the file with the model is cats-dogs-v2.tflite and it's in the current workdir in the image (see the Dockerfile above for the reference).\n",
    "\n",
    "__What's the image id of the base image?__\n",
    "\n",
    "In the build logs (on Linux), you'll see a log like that:\n",
    "\n",
    "```sh\n",
    "$ docker some-command-for-building\n",
    "Sending build context to Docker daemon  2.048kB\n",
    "Step 1/N : FROM agrigorev/zoomcamp-cats-dogs-lambda:v2\n",
    " ---> XXXXXXXXXXXX\n",
    "Step 2/N : ....\n",
    "```\n",
    "\n",
    "You need to get this XXXXXXXXXXXX.\n",
    "\n",
    "On MacOS and Windows, the logs for docker build are different. To get the image id there, you can use docker image ls -a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7b9fc-4c3b-4818-afb3-591a52b49511",
   "metadata": {},
   "source": [
    "__*Answer Q5: 322fc756f258*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8fe87-6e2e-4771-a006-f9d638531904",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Now run the container locally.\n",
    "\n",
    "Score this image: [upload.wikimedia.org/wikipedia/commons/1/18/Vombatus_ursinus_-Maria_Island_National_Park.jpg](https://upload.wikimedia.org/wikipedia/commons/1/18/Vombatus_ursinus_-Maria_Island_National_Park.jpg)\n",
    "\n",
    "__What's the output from the model?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a4d27-a42d-45e9-b36e-41daa575d797",
   "metadata": {},
   "source": [
    "__*Answer Q6: 0.5413472652435303*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02af71-edbe-4c1d-aac4-6b11a3f8d386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_kernel",
   "language": "python",
   "name": "tensorflow_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
