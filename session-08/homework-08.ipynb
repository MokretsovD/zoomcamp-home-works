{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade23670-f0be-4731-b1c0-bd35e684dd1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework\n",
    "\n",
    "## Dataset\n",
    "In this homework, we'll build a model for predicting if we have an image of a dog or a cat. For this, we will use the \"Dogs & Cats\" dataset that can be downloaded from Kaggle.\n",
    "\n",
    "You need to download the train.zip file.\n",
    "\n",
    "If you have troubles downloading from Kaggle, use this link instead:\n",
    "\n",
    "wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch.\n",
    "\n",
    "Note: You don't need a computer with a GPU for this homework. A laptop or any personal computer should be sufficient.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "The dataset contains 12,500 images of cats and 12,500 images of dogs.\n",
    "\n",
    "Now we need to split this data into train and validation\n",
    "\n",
    "Create a train and validation folders\n",
    "In each folder, create cats and dogs folders\n",
    "Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
    "\n",
    "Move the remaining 2,500 images to the validation folder (from 10000 to 12499)\n",
    "You can do this manually or with Python (check os and shutil packages).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f20d17-76c1-4d98-9c90-993abf982f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-21 13:41:58--  https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-releases.githubusercontent.com/426348925/f39169c9-5f22-4a57-bb37-495c0d2974ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211121%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211121T124158Z&X-Amz-Expires=300&X-Amz-Signature=4b29fa56afa8ec52657660ed9bac52790edc889cd74acf70eb54bf47728ef585&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dtrain.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-11-21 13:41:58--  https://github-releases.githubusercontent.com/426348925/f39169c9-5f22-4a57-bb37-495c0d2974ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211121%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211121T124158Z&X-Amz-Expires=300&X-Amz-Signature=4b29fa56afa8ec52657660ed9bac52790edc889cd74acf70eb54bf47728ef585&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dtrain.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
      "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 569546721 (543M) [application/octet-stream]\n",
      "Saving to: ‘train.zip’\n",
      "\n",
      "train.zip           100%[===================>] 543.16M  12.6MB/s    in 44s     \n",
      "\n",
      "2021-11-21 13:42:43 (12.3 MB/s) - ‘train.zip’ saved [569546721/569546721]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip -O train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94649892-591c-43b7-b573-6db9d8b382b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qo 'train.zip' -d 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ab5f96-8a2e-4f5e-9034-d25d8b9b96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 'train'\n",
    "!mkdir 'train/cats'\n",
    "!mkdir 'train/dogs'\n",
    "!mkdir 'validation'\n",
    "!mkdir 'validation/cats'\n",
    "!mkdir 'validation/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578133a9-88d1-4f68-b272-36cab19458f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash -c 'mv data/train/cat.{0..9999}.jpg train/cats'\n",
    "!bash -c 'mv data/train/dog.{0..9999}.jpg train/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70bbcb24-f8e7-4225-b418-2d22171e708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash -c 'mv data/train/cat.{10000..12499}.jpg validation/cats'\n",
    "!bash -c 'mv data/train/dog.{10000..12499}.jpg validation/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72c2497-8b3c-4580-9605-78f88f3c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -drf data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cb435-4d5b-40ca-ad02-2fb002b3d7f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "For this homework we will use Convolutional Neural Network (CNN. Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be (150, 150, 3)\n",
    "* Next, create a covolutional layer (Conv2D):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be (3, 3) (that's the size of the filter)\n",
    "    * Use 'relu' as activation\n",
    "* Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
    "    * Set the pooling size to (2, 2)\n",
    "* Turn the multi-dimensional result into vectors using a Flatten layer\n",
    "* Next, add a Dense layer with 64 neurons and 'relu' activation\n",
    "* Finally, create the Dense layer with 1 neuron - this will be the output\n",
    "\n",
    "As optimizer use SGD with the following parameters:\n",
    "\n",
    "* SGD(lr=0.002, momentum=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04788cee-c54b-4b15-8a11-511919ead248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93217048-7032-44df-9667-e97cf80cbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inputs = keras.layers.Input(shape=(150,150,3))\n",
    "\n",
    "    conv = keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(inputs)\n",
    "\n",
    "    pool = keras.layers.MaxPooling2D(pool_size=(2,2))(conv)\n",
    "\n",
    "    vectors = keras.layers.Flatten()(pool)\n",
    "\n",
    "    dense = keras.layers.Dense(64, activation='relu')(vectors)\n",
    "\n",
    "    outputs = keras.layers.Dense(1,activation='sigmoid')(dense)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca67a6d-ad15-4f2d-9f85-9805092aac20",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "__Since we have a binary classification problem, what is the best loss function for us?__\n",
    "\n",
    "__*Answer Q1: BinaryCrossentropy*__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f461a-99f4-40f3-8a49-94e0446a9caf",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "__What's the total number of parameters of the model? You can use the summary method for that.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c46cae-8657-43a6-8cd9-a6df904d27cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 13:43:14.444809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-21 13:43:14.444938: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-21 13:43:14.445013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2021-11-21 13:43:14.466647: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c107a0-7771-4c00-a875-e382b1d03a2f",
   "metadata": {},
   "source": [
    "__*Answer Q2: 11,215,873*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c063c-cc2d-4ccd-8d06-dc5e2b91bf40",
   "metadata": {},
   "source": [
    "## Generators and Training\n",
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "We don't need to do any additional pre-processing for the images.\n",
    "\n",
    "For training use .fit() with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc32edee-1547-418b-9261-0d23685b8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a38680-85f3-4e1e-922b-83c33e2a72de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_generator.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150,150),\n",
    "  #  classes=['dogs','cats'],\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = validation_generator.flow_from_directory(\n",
    "    './validation',\n",
    "    target_size=(150,150),\n",
    " #   classes=['dogs','cats'],\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69043f27-eaec-425b-95af-9c19886090d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cats': 0, 'dogs': 1}, {'cats': 0, 'dogs': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices, val_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f2dde52-8c8f-4d03-8e71-3bd141a4f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 13:43:15.268936: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/100 [..............................] - ETA: 49s - loss: 0.6879 - accuracy: 0.5500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 13:43:15.595890: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56074240 exceeds 10% of free system memory.\n",
      "2021-11-21 13:43:15.696212: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56074240 exceeds 10% of free system memory.\n",
      "2021-11-21 13:43:15.777825: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56074240 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/100 [..............................] - ETA: 11s - loss: 0.6965 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 13:43:15.829969: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56074240 exceeds 10% of free system memory.\n",
      "2021-11-21 13:43:15.891345: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 56074240 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6986 - accuracy: 0.4790 - val_loss: 0.6970 - val_accuracy: 0.0090\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.6937 - accuracy: 0.4875 - val_loss: 0.6979 - val_accuracy: 0.1810\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.6929 - accuracy: 0.5095 - val_loss: 0.6981 - val_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.6926 - accuracy: 0.5290 - val_loss: 0.7219 - val_accuracy: 0.0180\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.6904 - accuracy: 0.5350 - val_loss: 0.6781 - val_accuracy: 0.5970\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.6849 - accuracy: 0.5600 - val_loss: 0.7816 - val_accuracy: 0.1160\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.6723 - accuracy: 0.5830 - val_loss: 0.7086 - val_accuracy: 0.4540\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.6720 - accuracy: 0.5820 - val_loss: 0.7544 - val_accuracy: 0.3170\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.6654 - accuracy: 0.5845 - val_loss: 0.7423 - val_accuracy: 0.3830\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.6614 - accuracy: 0.5960 - val_loss: 0.7217 - val_accuracy: 0.4190\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c57cce-4d72-4754-9e9a-3739af625a76",
   "metadata": {},
   "source": [
    "## Question 3  \n",
    "\n",
    "__What is the median of training accuracy for this model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "657b3033-9ccd-44b8-9e2f-1ef3c11bdb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5475000143051147"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f82c3e-08f8-4398-9048-6acaa5465cb2",
   "metadata": {},
   "source": [
    "__*Answer Q3: 0.55*__  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e000f-82fb-4981-9a23-cecb1e73280b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "__What is the standard deviation of training loss for this model?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386d724e-cd1d-4fc1-a73d-0000d7883d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012723315232945192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a222a-8a54-40e2-9946-29440f704654",
   "metadata": {},
   "source": [
    "__*Answer Q4: 0.012*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d7778-18f8-45b5-9559-db92e48cea10",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* rotation_range=40,\n",
    "* width_shift_range=0.2,\n",
    "* height_shift_range=0.2,\n",
    "* shear_range=0.2,\n",
    "* zoom_range=0.2,\n",
    "* horizontal_flip=True,\n",
    "* fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6670d0b9-5db0-4341-a8ef-1b6b467a84b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,    \n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_ds = train_generator.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    ")\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = validation_generator.flow_from_directory(\n",
    "    './validation',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size=20,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc30a73-93dd-4564-b1c8-19a7559511c2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "__What is the mean of validation loss for the model trained with augmentations?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f0daa71-b660-46eb-b09d-7907c22120ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.6728 - accuracy: 0.5765 - val_loss: 0.6154 - val_accuracy: 0.6600\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 0.6814 - accuracy: 0.5555 - val_loss: 0.7038 - val_accuracy: 0.4510\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.6739 - accuracy: 0.5670 - val_loss: 0.7731 - val_accuracy: 0.2850\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.6667 - accuracy: 0.5880 - val_loss: 0.5731 - val_accuracy: 0.7850\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6747 - accuracy: 0.5580 - val_loss: 0.6275 - val_accuracy: 0.7350\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.6633 - accuracy: 0.5965 - val_loss: 0.5363 - val_accuracy: 0.8390\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.6683 - accuracy: 0.5785 - val_loss: 0.9571 - val_accuracy: 0.1310\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 0.6638 - accuracy: 0.5965 - val_loss: 0.5842 - val_accuracy: 0.7510\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.6586 - accuracy: 0.5890 - val_loss: 0.5542 - val_accuracy: 0.8110\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6602 - accuracy: 0.6030 - val_loss: 0.5618 - val_accuracy: 0.8270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2042d520-2c21-471b-af83-e2eade59815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486403346061707"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2898011-39ea-44db-a715-f5ff9e5c59fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "__*Answer Q5: 0.65*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bd58b-9cd8-48ec-8df0-ee936917c114",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "__What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf30af48-8487-42a4-aa69-9416ae1e0b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717999964952469"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_accuracy'][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e2da5-92c2-434f-9c38-1e4add77b664",
   "metadata": {},
   "source": [
    "__*Answer Q6: 0.67*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb05ce-5529-4e39-96ae-305bc12a1f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_kernel",
   "language": "python",
   "name": "tensorflow_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
